{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of TensorFlow with GPU",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMce8muBqXQP"
      },
      "source": [
        "# Dogs-vs-Cats - Kaggle\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHl62bBJVTvQ"
      },
      "source": [
        "In this project, you'll write an algorithm to classify whether images contain either a dog or a cat. We'll be using this dataset https://www.kaggle.com/c/dogs-vs-cats/data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BpPWmbnrbUIF",
        "outputId": "309ccf4a-1fe2-49b1-a539-e324c3686676"
      },
      "source": [
        "%tensorflow_version 2.x\r\n",
        "import tensorflow as tf\r\n",
        "device_name = tf.test.gpu_device_name()\r\n",
        "if device_name != '/device:GPU:0':\r\n",
        "  raise SystemError('GPU device not found')\r\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "giZi3CLH5yhb"
      },
      "source": [
        "# Import all required modules\r\n",
        "\r\n",
        "import tensorflow as tf\r\n",
        "import keras\r\n",
        "from os import getcwd\r\n",
        "\r\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\r\n",
        "from tensorflow.keras.models import Sequential, load_model\r\n",
        "from tensorflow.keras.optimizers import Adam\r\n",
        "from tensorflow.keras.callbacks import TensorBoard, ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\r\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\r\n",
        "import cv2\r\n",
        "import numpy as np\r\n",
        "from tqdm import tqdm\r\n",
        "import os\r\n",
        "from random import shuffle\r\n",
        "from time import time\r\n",
        "from matplotlib import pyplot\r\n",
        "from matplotlib.image import imread"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L68Kg0JnAoGS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b65be902-73d3-426c-bda4-8f591ed94843"
      },
      "source": [
        "# link google drive where the dataset is placed\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMn5Z-YhWy_J"
      },
      "source": [
        "#### Load the data\r\n",
        "The dataset is available in two parts, training and testing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtPdRBszk992"
      },
      "source": [
        "train_path = '/content/drive/MyDrive/Colab Notebooks/Dogs-vs-Cats_Classifier/Dogs-Cats-Dataset/train_images'\r\n",
        "test_path = '/content/drive/MyDrive/Colab Notebooks/Dogs-vs-Cats_Classifier/Dogs-Cats-Dataset/test_images'"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7l7VX-Uuem3e"
      },
      "source": [
        "#### Image Labeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqqwP5cPekDa"
      },
      "source": [
        "def get_label(imag):\r\n",
        "    \"\"\"\r\n",
        "    Argument:\r\n",
        "    imag - The name of the image whose label we want to get\r\n",
        "    \r\n",
        "    Return:\r\n",
        "    respective label for cat or dog (cat = 0, dog = 1,)\r\n",
        "    \"\"\"\r\n",
        "    term = imag.split('.')[0]\r\n",
        "    if term == 'cat':\r\n",
        "        return [0]\r\n",
        "    else:\r\n",
        "        return [1]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeRKm6nX6WYe"
      },
      "source": [
        "# Hyperparameters \r\n",
        "IMG_SIZE = 50\r\n",
        "LR = 0.0003\r\n",
        "BATCH_SIZE = 32"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaXUIxv8hdTp"
      },
      "source": [
        "def get_training_data():\r\n",
        "    \"\"\"Returns the training data from train_path.\r\n",
        "    Images are read in grayscale format and resized to IMG_SIZE dimension square.\r\n",
        "    The whole data is saved with numpy in .npy format for quick loading for future purpose.\r\n",
        "    \"\"\"\r\n",
        "    training_data = []\r\n",
        "    if os.path.isfile('training_data_{}.npy'.format(IMG_SIZE)):\r\n",
        "        return np.load('training_data_{}.npy'.format(IMG_SIZE))\r\n",
        "    else:\r\n",
        "        for img in tqdm(os.listdir(train_path)):\r\n",
        "            label = get_label(img)\r\n",
        "            path = os.path.join(train_path,img)\r\n",
        "            img = cv2.resize(cv2.imread(path,cv2.IMREAD_GRAYSCALE), (IMG_SIZE,IMG_SIZE))\r\n",
        "            img = img/255\r\n",
        "            training_data.append([np.array(img),np.array(label)])\r\n",
        "        shuffle(training_data)\r\n",
        "        np.save('training_data_{}.npy'.format(IMG_SIZE),training_data)\r\n",
        "        return np.array(training_data)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9P6kHenWrBeJ"
      },
      "source": [
        "def get_testing_data():\r\n",
        "    \"\"\"Returns the testing data from test_path.\r\n",
        "    Images are read in grayscale format and resized to IMG_SIZE dimension square.\r\n",
        "    The whole data is saved with numpy in .npy format for quick loading for future purpose.\r\n",
        "    \"\"\"\r\n",
        "    testing_data = []\r\n",
        "    if os.path.isfile('testing_data_{}.npy'.format(IMG_SIZE)):\r\n",
        "        return np.load('testing_data_{}.npy'.format(IMG_SIZE))\r\n",
        "    else:\r\n",
        "        for img in tqdm(os.listdir(test_path)):\r\n",
        "            img_id = int(img.split('.')[0])\r\n",
        "            path = os.path.join(test_path,img)\r\n",
        "            img = cv2.resize(cv2.imread(path,cv2.IMREAD_GRAYSCALE), (IMG_SIZE,IMG_SIZE))\r\n",
        "            img = img/255\r\n",
        "            testing_data.append([np.array(img),img_id])\r\n",
        "        testing_data.sort(key = lambda x: x[1])\r\n",
        "        np.save('testing_data_{}.npy'.format(IMG_SIZE),testing_data)\r\n",
        "        return np.array(testing_data)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfS2ukIp5qI7"
      },
      "source": [
        "#### Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYH5lKJotcoo",
        "outputId": "6b6d4f66-60f0-4e67-cb3c-a1247828c747"
      },
      "source": [
        "data = get_training_data()\r\n",
        "\r\n",
        "partition = 1000             # Breaking -ve index\r\n",
        "train = data[:-partition]    # For Training purpose\r\n",
        "test= data[-partition:]      # For Validation purpose\r\n",
        "\r\n",
        "# Training set\r\n",
        "X_train = np.array([i[0] for i in train]).reshape(-1,IMG_SIZE,IMG_SIZE,1)\r\n",
        "y_train = np.array([i[1] for i in train])\r\n",
        "\r\n",
        "# Validation set\r\n",
        "X_val = np.array([i[0] for i in test]).reshape(-1,IMG_SIZE,IMG_SIZE,1)\r\n",
        "y_val = np.array([i[1] for i in test])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 24254/24254 [1:41:33<00:00,  3.98it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfG-dn2W559f"
      },
      "source": [
        "#### Image Augmentation for better results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOFrOUuKuElX"
      },
      "source": [
        "\"\"\"Effects added on image\r\n",
        "    Rotation - ± 50 deegrees,\r\n",
        "    Width Shift - ± 15 %\r\n",
        "    Height Shift - ± 15 %\r\n",
        "    Zoom - 30%\r\n",
        "    Horizontal Flip\r\n",
        "    Vertical Flip\r\n",
        "\"\"\"\r\n",
        "datagen = ImageDataGenerator(rotation_range=20,width_shift_range=0.05,height_shift_range=0.05,\r\n",
        "                            zoom_range=0.05,horizontal_flip=True,vertical_flip=False)\r\n",
        "\r\n",
        "# Calculation of necessary internal data for all images.\r\n",
        "datagen.fit(X_train)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmZdXcu-6mTo"
      },
      "source": [
        "### NN Model definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cT5CLQa06bSj"
      },
      "source": [
        "def get_model(saved=True):\r\n",
        "    \"\"\"This method returns the model used.\r\n",
        "    Returns a saved model if MODEL_NAME is found.\r\n",
        "    CovNet Architecture\r\n",
        "    \r\n",
        "    Arguments:\r\n",
        "    saved - Get the saved model from the MODEL_PATH if exists.(default True)\r\n",
        "    \r\n",
        "    Returns:\r\n",
        "    model - The complete uncompiled Keras model.\r\n",
        "    \"\"\"\r\n",
        "    # tf.reset_default_graph()\r\n",
        "    \r\n",
        "    if os.path.isfile(MODEL_PATH) and saved :\r\n",
        "        print(\"Loading saved model {}\".format(MODEL_NAME))\r\n",
        "        return load_model(MODEL_PATH)\r\n",
        "    \r\n",
        "    # Declaring model\r\n",
        "    model = Sequential()\r\n",
        "\r\n",
        "    # 1st Block\r\n",
        "    model.add(Conv2D(input_shape=(IMG_SIZE, IMG_SIZE, 1),filters=128, kernel_size=5, strides=1,padding='same',name = 'blk1_conv1'))\r\n",
        "    model.add(Conv2D(filters=128, kernel_size=5, strides=1,padding='same',name = 'blk1_conv2'))\r\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), strides=2,name = 'blk1_mxPool'))\r\n",
        "\r\n",
        "    # 2nd Block\r\n",
        "    model.add(Conv2D(filters=64, kernel_size=5, strides=1,padding='same',name = 'blk2_conv1'))\r\n",
        "    model.add(Conv2D(filters=64, kernel_size=5, strides=1,padding='same',name = 'blk2_conv2'))\r\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), strides=2,name = 'blk2_mxPool'))\r\n",
        "    \r\n",
        "    # 3rd Block\r\n",
        "    model.add(Conv2D(filters=32, kernel_size=5, strides=1,padding='same',name = 'blk3_conv1'))\r\n",
        "    model.add(Conv2D(filters=32, kernel_size=5, strides=1,padding='same',name = 'blk3_conv2'))\r\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), strides=2,name = 'blk3_mxPool'))\r\n",
        "\r\n",
        "    # 4th Block - FC Block\r\n",
        "    dr_rate = 0.35\r\n",
        "    model.add(Flatten(name = 'blk4_flatten'))\r\n",
        "    model.add(Dropout(dr_rate,name = 'blk4_droupout1'))\r\n",
        "    model.add(Dense(512, activation='relu',name = 'blk4_dense1'))\r\n",
        "    model.add(Dropout(dr_rate,name = 'blk4_droupout2'))\r\n",
        "    model.add(Dense(128, activation='relu',name = 'blk4_dense2'))\r\n",
        "    model.add(Dropout(dr_rate,name = 'blk4_droupout3'))\r\n",
        "    model.add(Dense(1, activation='sigmoid',name = 'blk4_dense3'))\r\n",
        "\r\n",
        "    return model"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmZFMZg_7PXs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38b3e744-8c51-4f4c-b28b-5d3ded4af53b"
      },
      "source": [
        "model = get_model()\r\n",
        "model.summary()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "blk1_conv1 (Conv2D)          (None, 50, 50, 128)       3328      \n",
            "_________________________________________________________________\n",
            "blk1_conv2 (Conv2D)          (None, 50, 50, 128)       409728    \n",
            "_________________________________________________________________\n",
            "blk1_mxPool (MaxPooling2D)   (None, 25, 25, 128)       0         \n",
            "_________________________________________________________________\n",
            "blk2_conv1 (Conv2D)          (None, 25, 25, 64)        204864    \n",
            "_________________________________________________________________\n",
            "blk2_conv2 (Conv2D)          (None, 25, 25, 64)        102464    \n",
            "_________________________________________________________________\n",
            "blk2_mxPool (MaxPooling2D)   (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "blk3_conv1 (Conv2D)          (None, 12, 12, 32)        51232     \n",
            "_________________________________________________________________\n",
            "blk3_conv2 (Conv2D)          (None, 12, 12, 32)        25632     \n",
            "_________________________________________________________________\n",
            "blk3_mxPool (MaxPooling2D)   (None, 6, 6, 32)          0         \n",
            "_________________________________________________________________\n",
            "blk4_flatten (Flatten)       (None, 1152)              0         \n",
            "_________________________________________________________________\n",
            "blk4_droupout1 (Dropout)     (None, 1152)              0         \n",
            "_________________________________________________________________\n",
            "blk4_dense1 (Dense)          (None, 512)               590336    \n",
            "_________________________________________________________________\n",
            "blk4_droupout2 (Dropout)     (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "blk4_dense2 (Dense)          (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "blk4_droupout3 (Dropout)     (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "blk4_dense3 (Dense)          (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 1,453,377\n",
            "Trainable params: 1,453,377\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pg1h8VKt7RIE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "929569ed-7992-4af3-a570-2e0bd605cce5"
      },
      "source": [
        "# Optimizer (Adam Optimizer)\r\n",
        "adam = Adam(lr = LR)\r\n",
        "\r\n",
        "# Callbacks Declared\r\n",
        "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(time()),batch_size=BATCH_SIZE)\r\n",
        "       #Supported in new version of keras ,update_freq='epoch')\r\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.3,patience=3,verbose=1,\r\n",
        "                              mode='max', min_lr=0.000001)\r\n",
        "early_stop = EarlyStopping(monitor='val_loss',patience=3,verbose=1,mode='min')\r\n",
        "      #Supported in new version of keras ,restore_best_weights=True)\r\n",
        "model_checkpoint = ModelCheckpoint(filepath=MODEL_PATH,monitor='val_accuracy',verbose=1,save_best_only=True,\r\n",
        "                                  mode='max',period=3)\r\n",
        "\r\n",
        "model.compile(optimizer = adam,loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`batch_size` is no longer needed in the `TensorBoard` Callback and will be ignored in TensorFlow 2.0.\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWb8kV5I7KNl"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Unydh8l27UgT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f6e3d25-2e0a-460a-a2c8-1c8518d6486e"
      },
      "source": [
        "generator_train = True\r\n",
        "EPOCHS = 30\r\n",
        "callbacks=[tensorboard,reduce_lr,early_stop,model_checkpoint]\r\n",
        "\r\n",
        "if generator_train:\r\n",
        "    print(f'Training model {MODEL_NAME} using Image Augmentation')\r\n",
        "    hist = model.fit_generator(datagen.flow(X_train,y_train,batch_size=BATCH_SIZE),\r\n",
        "                               steps_per_epoch=len(X_train)//BATCH_SIZE,epochs=EPOCHS,verbose=2,\r\n",
        "                               validation_data=(X_val,y_val),callbacks=callbacks)\r\n",
        "else:\r\n",
        "    print(f'Training model {MODEL_NAME} using normal image data provided')\r\n",
        "    hist = model.fit(X_train,y_train,epochs=EPOCHS,batch_size=BATCH_SIZE,validation_data=(X_val,y_val),\r\n",
        "                     verbose=2,callbacks=callbacks)\r\n",
        "# model.save(MODEL_PATH)     "
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training model dogs_cats_LR-0.0003_MODEL-CovNet-128(2)-64(2)-32(2)-512-128-1.h5 using Image Augmentation\n",
            "Epoch 1/30\n",
            "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0185s vs `on_train_batch_end` time: 0.0513s). Check your callbacks.\n",
            "726/726 - 18s - loss: 0.3233 - accuracy: 0.8571 - val_loss: 0.3343 - val_accuracy: 0.8470\n",
            "Epoch 2/30\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.85600\n",
            "726/726 - 18s - loss: 0.3226 - accuracy: 0.8599 - val_loss: 0.3316 - val_accuracy: 0.8520\n",
            "Epoch 3/30\n",
            "726/726 - 18s - loss: 0.3279 - accuracy: 0.8574 - val_loss: 0.3216 - val_accuracy: 0.8550\n",
            "Epoch 4/30\n",
            "726/726 - 17s - loss: 0.3230 - accuracy: 0.8591 - val_loss: 0.3267 - val_accuracy: 0.8550\n",
            "Epoch 5/30\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.85600\n",
            "726/726 - 17s - loss: 0.3249 - accuracy: 0.8552 - val_loss: 0.3269 - val_accuracy: 0.8550\n",
            "Epoch 6/30\n",
            "\n",
            "Epoch 00006: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
            "726/726 - 18s - loss: 0.3255 - accuracy: 0.8563 - val_loss: 0.3283 - val_accuracy: 0.8540\n",
            "Epoch 00006: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kf5tt7QW7XnA"
      },
      "source": [
        "### Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsqPm92o8P38",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fec241b-ee13-4d25-f59f-ef7b8864fa79"
      },
      "source": [
        "test_data = get_testing_data()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 12500/12500 [52:43<00:00,  3.95it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7JOAXbY8Qmt"
      },
      "source": [
        "X_test = np.array([i[0] for i in test_data]).reshape(-1,IMG_SIZE,IMG_SIZE,1)\r\n",
        "ids = [i[1] for i in test_data]"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9OPlfipg8S3F"
      },
      "source": [
        "pred = model.predict(X_test)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgccbUAt8Va8"
      },
      "source": [
        "filename = 'submission-{}.csv'.format(time())\r\n",
        "\r\n",
        "with open(filename,'w') as f:\r\n",
        "    f.write('id,label\\n')\r\n",
        "with open(filename,'a') as f:\r\n",
        "    for i in range(len(X_test)):\r\n",
        "        f.write('{},{}\\n'.format(ids[i],pred[i][0]))"
      ],
      "execution_count": 42,
      "outputs": []
    }
  ]
}